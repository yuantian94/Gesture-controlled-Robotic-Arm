# Gesture-controlled-Robotic-Arm
The project focuses on designing and building a robotic arm that mimics human arm movements. It comprises Control, Software, Communications, and Hand/Myo Subsystems. Kinect technology sends arm movement signals to the mechanical arm. This robot improves user interface for people in dangerous situations, capturing human perspective and interactions.
![1687471510948](https://github.com/yuantian94/Gesture-controlled-Robotic-Arm/assets/13746207/286bab32-3457-4306-92f8-afa21645d873)

This collaborative project for ECEN 404 involves the contributions of Kevin Bradshaw, Fuhua Song, Yuan Tian, and Zhengshuai Zhang. The author of this repository assumes responsibility for designing the Kinect software, implementing the sampling algorithm, and contributing to the communication subsystem. The code in this repository solely encompasses the work attributed to the author.
![1687471738096](https://github.com/yuantian94/Gesture-controlled-Robotic-Arm/assets/13746207/242f8333-18e9-4988-a7d4-0d7c2a9a99f0)
![1687472306555](https://github.com/yuantian94/Gesture-controlled-Robotic-Arm/assets/13746207/d6de728d-09f4-4711-ae04-bad20a9b111a)

In addition to the code, this repository also contains the comprehensive final project report. This report serves as a complete record, documenting the entire project journey from initial planning to the development of the final product.
